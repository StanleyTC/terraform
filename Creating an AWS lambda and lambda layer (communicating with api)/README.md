# Creating an AWS lambda and lambda layer (communicating with api)

In this project, develop a lambda layer and a lambda layer in aws  terraform, 
the goal is to try to make this lambda communicated with a public API, which 
will return random images

### Updated code:

Due to internal issues, lambda was unable to communicate with the GOT,  which 
would be our API, so the lambda only aims return "Hello from Lambda"

![Amazon_Lambda_architecture_logo svg](https://user-images.githubusercontent.com/95464654/190665144-eb114713-aca8-46e9-aebe-982364ac9890.png)

## What is a lambda and a lambda layer?

### Lambda

Lambda is an aws service that lets you run code without provisioning or manage 
servers, ie it is a serverless role. The lambda function is a  way to host the 
developed backend.
The code is only executed when someone makes a request, so the billing is done 
by execution only, supports multiple languages schedule

### Lambda layer

The use of the lambda layer is for package management, that is, when we want a 
package we are working on to be managed for the lambda, we will use a layer so 
that it manage for lambda

## How was this project made?

Initially, a main.tf file was generated, in which we inform which  provider  we 
will use. We have a variables.tf file,  responsible  because  it  contains  the 
variables that will be used within the project, in this case, we will only have 
one variable for the provider, which we are calling in  main.tf;  an  outputs.tf 
file would be nice to add too, for information to be exposed, but we don't  need 
to generate this terraform compilation file; and finally a locals.tf to  define
path of lambdas and layers, and also some tags.

With that, we will create the lambda folder, called cat_api, it  is  a  folder,
where we will define the lambda code (the code was developed in python).
We will then have a handler, which will be the main function that will be called
when we fire the lambda

### Valid remember:

in this project there is only the README or the codes typed via the IDE, we will 
not have the files generated by terraform itself, only the necessary package files
for execution, even for security.

### We have our lambda ready, what do we need now?

Our lambda layer will be needed to manage it, although it is not present in this 
project, it is important to create  a  folder called layers,where we will have a 
folder for got, which would be the api used,  and inside the got folder,we would 
have a  nodejs call (these are  the  folders and files referenced in the layer.tf 
file, but we would have to download  all dependencies, like packages  and nodejs, 
where we would have dependencies).

### Lambda and layer resources

Now we will create the lambda resource and the layer resource. for that, we will 
have the lambda.tf file, where the resource will be defined,  with  the  name of
cat_api, we will define our handler too, we must insert the role for permissions, 
we'll explain more about that later, and also the runtime, as our  code  was  by 
python, will be given by python3.9.
The lambda is set, however it can't do anything yet, we should define the role,so 
we must create a file called iam.tf, where we will have all the necessary roles 
and policies

## iam.tf

![download-removebg-preview](https://user-images.githubusercontent.com/95464654/190679677-6a33a00a-4299-4ccd-bc33-8aaa47fea9a8.png)

Now we must define the necessary functions. initially we will create the aws_iam_role 
resource, in which  the name was given  as  cat_api_lambda,  the  name  was  set  to 
cat-api-lambda-role and tags were called locals.tf.
assume_role_policy will give lambdda the ability to assume a role, so we will need to 
create this property  (this property is created as "data" on line 1)  so  it  can  be 
referenced later)

We will have a  role defined for the lambda, but  it  cannot  do  nothing  more  than 
assuming this role, so we will need  to  create  another one policy  to  give  lambda 
permission to create logs inside cloudwatch, for that we will define this  policy, in 
line 22 of iam.tf, and the policy  will be created on line 44.

Now we have the policy and the role, however we will need to attach this policy with 
the role, and this is done on line 49, with the resource policy_attachment

Now that the permissions are set, we can reference in lambda.tf, that was missing.

## How to make code work in lambda?

With everything defined, our lambda will be created, but it won't have any code, since 
the code needs to be in zip, and for that we will need another data, which I defined as 
cat_api_artefact, where inside I put the zipped file with source_file, since it's just 
a file that will be zipped, hello.py (this is all happening inside the first block, on 
the line 1 from the lambda.tf file)

## Final step: layer

we will need to set our layer to finish the lambda, so we will create the layer.tf file, 
where we will create the null_resource resource for install layer dependencies.
Then I can create my layer, similar to how I created my lambda, with the  archive_file 
data, and with the name of got_layer, where we must define the type  and  source  that 
will need all the files generated inside the folder got, not present in this project 
uploaded to git.
Now we will need to create the resource of the layer itself, which will be on line 20 in
layer.tf, and we can reference it in lambda.tf, which allows it to be referenced for up 
to 5 layers.

### That's it! project done
